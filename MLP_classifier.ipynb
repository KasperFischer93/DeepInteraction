{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1177e1c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-19T17:10:35.363059Z",
     "iopub.status.busy": "2022-04-19T17:10:35.362197Z",
     "iopub.status.idle": "2022-04-19T17:10:38.525103Z",
     "shell.execute_reply": "2022-04-19T17:10:38.525630Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from plink_datasets import *\n",
    "from datasets import *\n",
    "from ANN_MCC import *\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as metrics\n",
    "import scikitplot as skplt\n",
    "import pickle\n",
    "import matplotlib.image as mpimg\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6923aab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_path = \"/home/user/directory/phenotypes/pheno.txt\"   \n",
    "data_path = \"/home/user/directory/model_runs/\"\n",
    "idx = \"600\"\n",
    "\n",
    "\n",
    "subprocess.call([\"/home/user/Phenotype_prediction/data_management/split_data.R\", idx, data_path],\n",
    "                   stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\n",
    "\n",
    "train_path = data_path + idx + \"/train\"\n",
    "g_train = merge_geno_pheno(geno_path = train_path,\n",
    "                           pheno_path = hos_path,\n",
    "                           delim = \" \")\n",
    "\n",
    "val_path = data_path + idx + \"/valid\"\n",
    "g_val = merge_geno_pheno(geno_path = val_path,\n",
    "                         pheno_path = hos_path,\n",
    "                         delim = \" \")\n",
    "\n",
    "test_path = data_path + idx + \"/test\"\n",
    "g_test = merge_geno_pheno(geno_path = test_path,\n",
    "                          pheno_path = hos_path,\n",
    "                          delim = \" \")\n",
    "\n",
    "gwas_data = PreSplit(G_train = g_train, \n",
    "                 G_val = g_val, \n",
    "                 G_test = g_test, \n",
    "                 scale=False,\n",
    "                 shuffle=True,\n",
    "                 shuffle_phenotype=False)\n",
    "\n",
    "\n",
    "X_train, y_train = gwas_data[\"train\"]\n",
    "w = torch.tensor(1 / y_train.mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6d3b6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Training loss: 6.169233322143555 Correlation: -0.06675314903259277\n",
      "Epoch: 2 Training loss: 5.228658676147461 Correlation: -0.04624195769429207\n",
      "Epoch: 3 Training loss: 5.081997394561768 Correlation: -0.05331677198410034\n",
      "Epoch: 4 Training loss: 2.9280364513397217 Correlation: -0.0038161154370754957\n",
      "Epoch: 5 Training loss: 2.783190965652466 Correlation: 0.004978541284799576\n",
      "Epoch: 6 Training loss: 2.181175947189331 Correlation: 0.003167770802974701\n",
      "Epoch: 7 Training loss: 2.0707356929779053 Correlation: 0.05559272691607475\n",
      "Epoch: 8 Training loss: 2.2267184257507324 Correlation: 0.033366769552230835\n",
      "Epoch: 9 Training loss: 2.3239798545837402 Correlation: 0.04952580854296684\n",
      "Epoch: 10 Training loss: 1.900946855545044 Correlation: 0.06058149412274361\n",
      "Epoch: 11 Training loss: 1.809238314628601 Correlation: 0.01725410670042038\n",
      "Epoch: 12 Training loss: 2.214118003845215 Correlation: 0.035829994827508926\n",
      "Epoch: 13 Training loss: 1.7634093761444092 Correlation: 0.018149331212043762\n",
      "Epoch: 14 Training loss: 1.7958756685256958 Correlation: 0.02127639763057232\n",
      "Epoch: 15 Training loss: 2.584014415740967 Correlation: 0.047798484563827515\n",
      "Epoch: 16 Training loss: 2.859734058380127 Correlation: 0.027487454935908318\n",
      "Epoch: 17 Training loss: 3.4365296363830566 Correlation: 0.03462916240096092\n",
      "Epoch: 18 Training loss: 2.4552695751190186 Correlation: 0.05739108845591545\n",
      "Epoch: 19 Training loss: 1.9226906299591064 Correlation: 0.06900312006473541\n",
      "Epoch: 20 Training loss: 2.2954442501068115 Correlation: 0.04191557690501213\n",
      "Epoch: 21 Training loss: 1.869748592376709 Correlation: 0.06676391512155533\n",
      "Epoch: 22 Training loss: 1.604827880859375 Correlation: 0.07275058329105377\n",
      "Epoch: 23 Training loss: 2.257690668106079 Correlation: 0.059573929756879807\n",
      "Epoch: 24 Training loss: 2.370577812194824 Correlation: 0.0034327793400734663\n",
      "Epoch: 25 Training loss: 2.1270253658294678 Correlation: 0.05523931607604027\n",
      "Epoch: 26 Training loss: 1.8338853120803833 Correlation: 0.042212579399347305\n",
      "Epoch: 27 Training loss: 1.8562841415405273 Correlation: 0.02327270247042179\n",
      "Epoch: 28 Training loss: 2.227790117263794 Correlation: 0.058006782084703445\n",
      "Epoch: 29 Training loss: 2.1137478351593018 Correlation: 0.026807742193341255\n",
      "Epoch: 30 Training loss: 1.40736722946167 Correlation: 0.05448266491293907\n",
      "Epoch: 31 Training loss: 1.7455629110336304 Correlation: 0.02884429134428501\n",
      "Epoch: 32 Training loss: 1.999610424041748 Correlation: 0.09807579964399338\n",
      "Epoch: 33 Training loss: 2.725250720977783 Correlation: 0.0301987174898386\n",
      "Epoch: 34 Training loss: 2.3331942558288574 Correlation: 0.034794751554727554\n",
      "Epoch: 35 Training loss: 1.484457015991211 Correlation: 0.060492295771837234\n",
      "Epoch: 36 Training loss: 1.846451997756958 Correlation: 0.06209402158856392\n",
      "Epoch: 37 Training loss: 2.702863931655884 Correlation: 0.059723708778619766\n",
      "Epoch: 38 Training loss: 2.65100359916687 Correlation: 0.022502467036247253\n",
      "Epoch: 39 Training loss: 1.7772934436798096 Correlation: 0.0771186575293541\n",
      "Epoch: 40 Training loss: 2.2744300365448 Correlation: 0.020959628745913506\n",
      "Epoch: 41 Training loss: 2.8915929794311523 Correlation: 0.07547882199287415\n",
      "Epoch: 42 Training loss: 2.469923973083496 Correlation: 0.053324099630117416\n",
      "Epoch: 43 Training loss: 2.161005973815918 Correlation: 0.04535916820168495\n",
      "Early stopping!\n"
     ]
    }
   ],
   "source": [
    "net = ANN(X_train.shape[1], [25], 1, act_func=nn.ReLU, mlp_m=True)\n",
    "trainloss_list, valloss_list, model = train(net=net,\n",
    "                                            dataset=gwas_data,\n",
    "                                            batch_size=300,\n",
    "                                            nepochs=150,\n",
    "                                            criterion=nn.BCEWithLogitsLoss(pos_weight=w),\n",
    "                                            evaluate=MCCLoss_bin,\n",
    "                                            test = test_mcc_bin,\n",
    "                                            learning_rate=5e-3,\n",
    "                                            l1_const=0,\n",
    "                                            l2_const=0.1,\n",
    "                                            early_stopping=True,\n",
    "                                            verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4a9775a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_performance = pd.DataFrame({'TRAIN_LOSS': np.asarray(trainloss_list), 'VAL_LOSS':  np.asarray(valloss_list)})\n",
    "train_performance.to_csv(data_path + idx + \"/train_performance.csv\", sep = \"\\t\", index = False)\n",
    "\n",
    "X_test, y_test = gwas_data[\"test\"]\n",
    "y_pred_raw = model(X_test)\n",
    "y_true = y_test.view(-1,1).numpy()\n",
    "test_performance = pd.DataFrame({'RAW_PRED': y_pred_raw.detach().numpy().flatten(), 'LABELS': y_true.flatten()})\n",
    "test_performance.to_csv(data_path + idx + \"/test_performance.csv\", sep = \"\\t\", index = False) \n",
    "\n",
    "torch.save(model, data_path + idx + \"/model_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529805d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
